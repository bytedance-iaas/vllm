{
  "tests": [
    {
      "test-id": 0,
      "enabled": true,
      "group": "PD分离",
      "name": "H20-PD",
      "description": "",
      "program": "benchmark",
      "backend": "openai-chat",
      "model": "/infinistore/Llama-3.1-8B-Instruct",
      "base-url": "http://127.0.0.1:8888",
      "endpoint": "/v1/chat/completions",
      "num-prompts": 10,
      "request-rate": 2,
      "percentile-metrics": "ttft,tpot,itl",
      "metric-percentiles": "50,90,95,99",
      "goodput": {
        "ttft": 5000,
        "tpot": 50
      },
      "max-concurrency": 200,
      "random-input-len": 2048,
      "random-output-len": 200,
      "random-prefix-len": 0,
      "random-range-ratio": 1.0,
      "dataset-name": "random",
      "dataset-path": "",
      "ignore-eos" : true,
      "gpu-metric-interval": 0.5,
      "profile": false,
      "tokenizer": ""
    },
    {
      "test-id": 1,
      "enabled": false,
      "group": "混合部署",
      "name": "H20",
      "description": "test case 1",
      "program": "benchmark",
      "backend": "openai-chat",
      "model": "/infinistore/Llama-3.1-8B-Instruct",
      "base-url": "http://127.0.0.1:8888",
      "endpoint": "/v1/chat/completions",
      "num-prompts": 200,
      "request-rate": 2.1,
      "percentile-metrics": "ttft,tpot,itl",
      "metric-percentiles": "50,90,95,99",
      "goodput": {
        "ttft": 5000,
        "tpot": 50
      },
      "max-concurrency": 200,
      "random-input-len": 2048,
      "random-output-len": 200,
      "random-prefix-len": 0,
      "random-range-ratio": 1.0,
      "dataset-name": "random",
      "dataset-path": "",
      "ignore-eos" : true,
      "gpu-metric-interval": 0.5,
      "profile": false,
      "tokenizer": ""
    },
    {
      "test-id": 2,
      "enabled": true,
      "group": "PD分离",
      "name": "H20-PD",
      "description": "",
      "program": "benchmark",
      "backend": "openai-chat",
      "model": "/infinistore/Llama-3.1-8B-Instruct",
      "base-url": "http://127.0.0.1:8888",
      "endpoint": "/v1/chat/completions",
      "num-prompts": 10,
      "request-rate": 2,
      "percentile-metrics": "ttft,tpot,itl",
      "metric-percentiles": "50,90,95,99",
      "goodput": {
        "ttft": 5000,
        "tpot": 50
      },
      "max-concurrency": 200,
      "random-input-len": 2048,
      "random-output-len": 200,
      "random-prefix-len": 0,
      "random-range-ratio": 1.0,
      "dataset-name": "random",
      "dataset-path": "",
      "ignore-eos" : true,
      "gpu-metric-interval": 0.5,
      "profile": false,
      "tokenizer": ""
    },
    {
      "test-id": 3,
      "enabled": false,
      "group": "PD分离",
      "name": "4090+H20-PD",
      "description": "",
      "program": "benchmark",
      "backend": "vllm",
      "model": "/data00/models/Meta-Llama-3.1-8B-Instruct",
      "base-url": "http://127.0.0.1:8099",
      "endpoint": "/v1/completions",
      "num-prompts": 200,
      "request-rate": 4.5,
      "percentile-metrics": "ttft,tpot,itl",
      "metric-percentiles": "50,90,95,99",
      "goodput": {
        "ttft": 5000,
        "tpot": 50
      },
      "max-concurrency": 200,
      "sharegpt-output-len": 200,
      "dataset-name": "sharegpt",
      "ignore-eos" : true,
      "gpu-metric-interval": 0.5,
      "tokenizer": ""
    },
    {
      "test-id": 4,
      "enabled": false,
      "group": "PD分离",
      "name": "4090+H20-PD-FP8",
      "program": "benchmark",
      "description": "",
      "backend": "tensorrt-llm",
      "model": "ensemble",
      "base-url": "http://localhost:8099",
      "endpoint": "/v2/models/ensemble/generate_stream",
      "num-prompts": 200,
      "request-rate": 10,
      "percentile-metrics": "ttft,tpot,itl",
      "metric-percentiles": "50,90,95,99",
      "goodput": {
        "ttft": 5000,
        "tpot": 50
      },
      "max-concurrency": 200,
      "sonnet-input-len": 2048,
      "sonnet-output-len": 1,
      "sonnet-prefix-len": 0,
      "dataset-name": "sonnet",
      "ignore-eos" : true,
      "tokenizer": "/data00/models/Meta-Llama-3.1-70B-Instruct/",
      "gpu-metric-interval": 0.5,
      "trust-remote-code": true
    },
    {
      "test-id": 5,
      "enabled": false,
      "group": "PrefixCache",
      "name": "混合部署测试",
      "description": "固定所有promopt中存在25%相同内容",
      "program": "benchmark",
      "backend": "vllm",
      "model": "/data00/models/Meta-Llama-3.1-8B-Instruct",
      "base-url": "http://localhost:8099",
      "endpoint": "/v1/completions",
      "num-prompts": 200,
      "request-rate": 1,
      "percentile-metrics": "ttft,tpot,itl",
      "metric-percentiles": "50,90,95,99",
      "goodput": {
        "ttft": 5000,
        "tpot": 50
      },
      "max-concurrency": 200,
      "hf-subset": "",
      "hf-split": "",
      "hf-output-len": 200,
      "dataset-name": "hf",
      "ignore-eos" : true,
      "random-prefix-len": 512,
      "gpu-metric-interval": 0.5,
      "tokenizer": ""
    },
    {
      "test-id": 6,
      "enabled": false,
      "group": "能力测试",
      "name": "prefill",
      "description": "",
      "program": "benchmark",
      "backend": "vllm",
      "model": "/data00/models/Meta-Llama-3.1-8B-Instruct",
      "base-url": "http://127.0.0.1:8099",
      "endpoint": "/v1/completions",
      "num-prompts": 200,
      "request-rate": 1,
      "percentile-metrics": "ttft,tpot,itl",
      "metric-percentiles": "50,90,95,99",
      "goodput": {
        "ttft": 5000,
        "tpot": 50
      },
      "max-concurrency": 200,
      "random-input-len": 2048,
      "random-output-len": 1,
      "dataset-name": "random",
      "tokenizer": "",
      "gpu-metric-interval": 0.5,
      "ignore-eos" : true
    },
    {
      "test-id": 7,
      "enabled": false,
      "group": "能力测试",
      "name": "decode",
      "program": "benchmark",
      "description": "不设置request-rate, 让所有请求同时达到",
      "backend": "vllm",
      "model": "/data00/models/Meta-Llama-3.1-8B-Instruct",
      "base-url": "http://127.0.0.1:8099",
      "endpoint": "/v1/completions",
      "num-prompts": 200,
      "percentile-metrics": "ttft,tpot,itl",
      "metric-percentiles": "50,90,95,99",
      "goodput": {
        "ttft": 5000,
        "tpot": 50
      },
      "request-rate": 0,
      "max-concurrency": 64,
      "random-input-len": 1,
      "random-output-len": 200,
      "dataset-name": "random",
      "tokenizer": "",
      "gpu-metric-interval": 0.5,
      "ignore-eos" : true
    }
  ]
}

